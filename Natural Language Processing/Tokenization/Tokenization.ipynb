{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "037b283b-245f-4aa9-ad90-65ef8115958d",
   "metadata": {},
   "source": [
    "NLTK:\n",
    "NLTK is a string processing library. It takes strings as input and returns strings or lists of strings as output. \n",
    "\n",
    "Spacy:\n",
    "Spacy uses object-oriented approach. When we parse a text, spaCy returns document object whose words and sentences are objects themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da1e596f-4659-4464-b075-6c82f59a3a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = '''\n",
    "Hello,\n",
    "My name is Rishikesh Krishna Patil.\n",
    "I'm from Mumbai,\n",
    "Currently, I am pursuing a CDAC Postgraduate Diploma in Artificial Intelligence. Through this course, I have gained significant knowledge in the AI domain and have learned technologies such as Machine Learning, Deep Learning, and Natural Language Processing. I have completed my graduation from Dy Patil, Navi Mumbai in Electronics in 2023.\n",
    "Regarding my hobbies, I enjoy playing both indoor and outdoor games, especially football. I was selected for the football team in 10th grade to represent our school. I played the defender's role, and our team was the runner-up, earning a silver medal.\n",
    "Thank you!\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4e8bb98-bed5-4424-85b0-71368425808a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hello,\n",
      "My name is Rishikesh Krishna Patil.\n",
      "I'm from Mumbai,\n",
      "Currently, I am pursuing a CDAC Postgraduate Diploma in Artificial Intelligence. Through this course, I have gained significant knowledge in the AI domain and have learned technologies such as Machine Learning, Deep Learning, and Natural Language Processing. I have completed my graduation from Dy Patil, Navi Mumbai in Electronics in 2023.\n",
      "Regarding my hobbies, I enjoy playing both indoor and outdoor games, especially football. I was selected for the football team in 10th grade to represent our school. I played the defender's role, and our team was the runner-up, earning a silver medal.\n",
      "Thank you!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c76cf7-0baf-446e-8821-b37e52045ed4",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "#### Paragraph to Sentence\n",
    "The sent_tokenize function is used to split a text into individual sentences. This is useful for tasks where sentence-level processing is required, such as sentiment analysis or machine translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05125897-32d9-4df4-a17b-18e52209b831",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09106156-2319-4953-950b-827bab019e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nHello,\\nMy name is Rishikesh Krishna Patil.',\n",
       " \"I'm from Mumbai,\\nCurrently, I am pursuing a CDAC Postgraduate Diploma in Artificial Intelligence.\",\n",
       " 'Through this course, I have gained significant knowledge in the AI domain and have learned technologies such as Machine Learning, Deep Learning, and Natural Language Processing.',\n",
       " 'I have completed my graduation from Dy Patil, Navi Mumbai in Electronics in 2023.',\n",
       " 'Regarding my hobbies, I enjoy playing both indoor and outdoor games, especially football.',\n",
       " 'I was selected for the football team in 10th grade to represent our school.',\n",
       " \"I played the defender's role, and our team was the runner-up, earning a silver medal.\",\n",
       " 'Thank you!']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = sent_tokenize(corpus)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dedd9ac-968c-41b6-b014-d39f7e5fb02c",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "#### Paragraph to words\n",
    "The word_tokenize function splits a sentence into individual words and punctuation. It's commonly used for preparing text for further processing like tagging or parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ef4ba23-3e94-4736-afd3-8336b1ad3af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "952a387e-e789-4979-bd1c-743375c3e1f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " ',',\n",
       " 'My',\n",
       " 'name',\n",
       " 'is',\n",
       " 'Rishikesh',\n",
       " 'Krishna',\n",
       " 'Patil',\n",
       " '.',\n",
       " 'I',\n",
       " \"'m\",\n",
       " 'from',\n",
       " 'Mumbai',\n",
       " ',',\n",
       " 'Currently',\n",
       " ',',\n",
       " 'I',\n",
       " 'am',\n",
       " 'pursuing',\n",
       " 'a',\n",
       " 'CDAC',\n",
       " 'Postgraduate',\n",
       " 'Diploma',\n",
       " 'in',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " '.',\n",
       " 'Through',\n",
       " 'this',\n",
       " 'course',\n",
       " ',',\n",
       " 'I',\n",
       " 'have',\n",
       " 'gained',\n",
       " 'significant',\n",
       " 'knowledge',\n",
       " 'in',\n",
       " 'the',\n",
       " 'AI',\n",
       " 'domain',\n",
       " 'and',\n",
       " 'have',\n",
       " 'learned',\n",
       " 'technologies',\n",
       " 'such',\n",
       " 'as',\n",
       " 'Machine',\n",
       " 'Learning',\n",
       " ',',\n",
       " 'Deep',\n",
       " 'Learning',\n",
       " ',',\n",
       " 'and',\n",
       " 'Natural',\n",
       " 'Language',\n",
       " 'Processing',\n",
       " '.',\n",
       " 'I',\n",
       " 'have',\n",
       " 'completed',\n",
       " 'my',\n",
       " 'graduation',\n",
       " 'from',\n",
       " 'Dy',\n",
       " 'Patil',\n",
       " ',',\n",
       " 'Navi',\n",
       " 'Mumbai',\n",
       " 'in',\n",
       " 'Electronics',\n",
       " 'in',\n",
       " '2023',\n",
       " '.',\n",
       " 'Regarding',\n",
       " 'my',\n",
       " 'hobbies',\n",
       " ',',\n",
       " 'I',\n",
       " 'enjoy',\n",
       " 'playing',\n",
       " 'both',\n",
       " 'indoor',\n",
       " 'and',\n",
       " 'outdoor',\n",
       " 'games',\n",
       " ',',\n",
       " 'especially',\n",
       " 'football',\n",
       " '.',\n",
       " 'I',\n",
       " 'was',\n",
       " 'selected',\n",
       " 'for',\n",
       " 'the',\n",
       " 'football',\n",
       " 'team',\n",
       " 'in',\n",
       " '10th',\n",
       " 'grade',\n",
       " 'to',\n",
       " 'represent',\n",
       " 'our',\n",
       " 'school',\n",
       " '.',\n",
       " 'I',\n",
       " 'played',\n",
       " 'the',\n",
       " 'defender',\n",
       " \"'s\",\n",
       " 'role',\n",
       " ',',\n",
       " 'and',\n",
       " 'our',\n",
       " 'team',\n",
       " 'was',\n",
       " 'the',\n",
       " 'runner-up',\n",
       " ',',\n",
       " 'earning',\n",
       " 'a',\n",
       " 'silver',\n",
       " 'medal',\n",
       " '.',\n",
       " 'Thank',\n",
       " 'you',\n",
       " '!']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = word_tokenize(corpus)\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2839c29-2022-46d0-ad20-862b85a9b23b",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "#### Sentences to words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd4f1125-c41d-4c9e-a4dc-88186ce88328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'My', 'name', 'is', 'Rishikesh', 'Krishna', 'Patil', '.']\n",
      "['I', \"'m\", 'from', 'Mumbai', ',', 'Currently', ',', 'I', 'am', 'pursuing', 'a', 'CDAC', 'Postgraduate', 'Diploma', 'in', 'Artificial', 'Intelligence', '.']\n",
      "['Through', 'this', 'course', ',', 'I', 'have', 'gained', 'significant', 'knowledge', 'in', 'the', 'AI', 'domain', 'and', 'have', 'learned', 'technologies', 'such', 'as', 'Machine', 'Learning', ',', 'Deep', 'Learning', ',', 'and', 'Natural', 'Language', 'Processing', '.']\n",
      "['I', 'have', 'completed', 'my', 'graduation', 'from', 'Dy', 'Patil', ',', 'Navi', 'Mumbai', 'in', 'Electronics', 'in', '2023', '.']\n",
      "['Regarding', 'my', 'hobbies', ',', 'I', 'enjoy', 'playing', 'both', 'indoor', 'and', 'outdoor', 'games', ',', 'especially', 'football', '.']\n",
      "['I', 'was', 'selected', 'for', 'the', 'football', 'team', 'in', '10th', 'grade', 'to', 'represent', 'our', 'school', '.']\n",
      "['I', 'played', 'the', 'defender', \"'s\", 'role', ',', 'and', 'our', 'team', 'was', 'the', 'runner-up', ',', 'earning', 'a', 'silver', 'medal', '.']\n",
      "['Thank', 'you', '!']\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences :\n",
    "    print(word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5e4d87-a032-4bca-bd54-98afa6cae93b",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "#### Sentences to words (punctuations treated as separate word)\n",
    "The wordpunct_tokenize function splits text into tokens using any non-alphanumeric character as a delimiter. This results in splitting punctuation from words, which might be useful in some text processing tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92e3f111-e887-49ca-819d-5a650bd96560",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "481f56f1-f72c-49b2-b439-81af1fc42490",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'My', 'name', 'is', 'Rishikesh', 'Krishna', 'Patil', '.', 'I', \"'\", 'm', 'from', 'Mumbai', ',', 'Currently', ',', 'I', 'am', 'pursuing', 'a', 'CDAC', 'Postgraduate', 'Diploma', 'in', 'Artificial', 'Intelligence', '.', 'Through', 'this', 'course', ',', 'I', 'have', 'gained', 'significant', 'knowledge', 'in', 'the', 'AI', 'domain', 'and', 'have', 'learned', 'technologies', 'such', 'as', 'Machine', 'Learning', ',', 'Deep', 'Learning', ',', 'and', 'Natural', 'Language', 'Processing', '.', 'I', 'have', 'completed', 'my', 'graduation', 'from', 'Dy', 'Patil', ',', 'Navi', 'Mumbai', 'in', 'Electronics', 'in', '2023', '.', 'Regarding', 'my', 'hobbies', ',', 'I', 'enjoy', 'playing', 'both', 'indoor', 'and', 'outdoor', 'games', ',', 'especially', 'football', '.', 'I', 'was', 'selected', 'for', 'the', 'football', 'team', 'in', '10th', 'grade', 'to', 'represent', 'our', 'school', '.', 'I', 'played', 'the', 'defender', \"'\", 's', 'role', ',', 'and', 'our', 'team', 'was', 'the', 'runner', '-', 'up', ',', 'earning', 'a', 'silver', 'medal', '.', 'Thank', 'you', '!']\n"
     ]
    }
   ],
   "source": [
    "print(wordpunct_tokenize(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e987cb-9f49-44e5-b6b6-d06274531efe",
   "metadata": {},
   "source": [
    "## Word Tokenization using Penn Treebank conventions\n",
    "The TreebankWordTokenizer is a more sophisticated tokenizer that uses the conventions of the Penn Treebank corpus. It handles punctuation and special cases more effectively than basic word tokenizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a28787b7-82f0-4d85-8f6d-6f557967f075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'My', 'name', 'is', 'Rishikesh', 'Krishna', 'Patil.', 'I', \"'m\", 'from', 'Mumbai', ',', 'Currently', ',', 'I', 'am', 'pursuing', 'a', 'CDAC', 'Postgraduate', 'Diploma', 'in', 'Artificial', 'Intelligence.', 'Through', 'this', 'course', ',', 'I', 'have', 'gained', 'significant', 'knowledge', 'in', 'the', 'AI', 'domain', 'and', 'have', 'learned', 'technologies', 'such', 'as', 'Machine', 'Learning', ',', 'Deep', 'Learning', ',', 'and', 'Natural', 'Language', 'Processing.', 'I', 'have', 'completed', 'my', 'graduation', 'from', 'Dy', 'Patil', ',', 'Navi', 'Mumbai', 'in', 'Electronics', 'in', '2023.', 'Regarding', 'my', 'hobbies', ',', 'I', 'enjoy', 'playing', 'both', 'indoor', 'and', 'outdoor', 'games', ',', 'especially', 'football.', 'I', 'was', 'selected', 'for', 'the', 'football', 'team', 'in', '10th', 'grade', 'to', 'represent', 'our', 'school.', 'I', 'played', 'the', 'defender', \"'s\", 'role', ',', 'and', 'our', 'team', 'was', 'the', 'runner-up', ',', 'earning', 'a', 'silver', 'medal.', 'Thank', 'you', '!']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer as tbwt\n",
    "\n",
    "tokenizer = tbwt()\n",
    "print(tokenizer.tokenize(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0077d6c1-1a0f-402d-8274-3c0be9a0ee82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
